{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# North Korean News\n",
    "\n",
    "Scrape the North Korean news agency http://kcna.kp\n",
    "\n",
    "Save a CSV called `nk-news.csv`. This file should include:\n",
    "\n",
    "* The **article headline**\n",
    "* The value of **`onclick`** (they don't have normal links)\n",
    "* The **article ID** (for example, the article ID for `fn_showArticle(\"AR0125885\", \"\", \"NT00\", \"L\")` is `AR0125885`\n",
    "\n",
    "The last part is easiest using pandas. Be sure you don't save the index!\n",
    "\n",
    "* _**Tip:** If you're using requests+BeautifulSoup, you can always look at response.text to see if the page looks like what you think it looks like_\n",
    "* _**Tip:** Check your URL to make sure it is what you think it should be!_\n",
    "* _**Tip:** Does it look different if you scrape with BeautifulSoup compared to if you scrape it with Selenium?_\n",
    "* _**Tip:** For the last part, how do you pull out part of a string from a longer string?_\n",
    "* _**Tip:** `expand=False` is helpful if you want to assign a single new column when extracting_\n",
    "* _**Tip:** `(` and `)` mean something special in regular expressions, so you have to say \"no really seriously I mean `(`\" by using `\\(` instead_\n",
    "* _**Tip:** if your `.*` is taking up too much stuff, you can try `.*?` instead, which instead of \"take as much as possible\" it means \"take only as much as needed\"_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lxml\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('http://kcna.kp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_link_text(\"English\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_list = []\n",
    "a_tags = driver.find_elements_by_tag_name(\"a\")\n",
    "for oclick in a_tags:\n",
    "    try:\n",
    "        head = oclick.text.strip()\n",
    "#         print(head)\n",
    "        art_ID = oclick.get_attribute('onclick')\n",
    "        if head == \"\":\n",
    "            try:\n",
    "                head = oclick.find_element_by_tag_name('img').get_attribute('title')\n",
    "#                 print(oclick.find_element_by_tag_name('img').get_attribute('title'))\n",
    "            except:\n",
    "                pass\n",
    "#         print(\"------\")\n",
    "    except:\n",
    "        pass\n",
    "    art_dict = {\n",
    "        'header': head,\n",
    "        'art_ID': art_ID\n",
    "    }\n",
    "    news_list.append(art_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(news_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"nkn\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"nkn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khanfazil/.pyenv/versions/3.7.1/lib/python3.7/site-packages/pandas/core/strings.py:2001: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "df1 = df1[~df1.art_ID.str.contains(\"(^fn_convert\\w.+?)\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[df1.art_ID.str.contains(\"^fn_showArticle\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[~df1.art_ID.str.contains(\"^fn_showArticle\\('',\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[df1.header.str.contains(\"^\\w.+?\\s\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[~df1.header.str.contains(\"News of 80-day Campaign\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for some reason regex stopped working for articles with no ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[~df1.header.str.contains(\"Education & Public Health\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[~df1.header.str.contains(\"Top News\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[~df1.header.str.contains(\"Science & Technology\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[~df1.header.str.contains(\"Supreme Leader's Activities\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[~df1.header.str.contains(\"Latest News\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[~df1.header.str.contains(\"International Relations\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['article_ID'] = df1.art_ID.str.extract(\"(\\w\\w\\d\\d\\d\\d\\d\\d\\d)\", expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"nk-news.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-Ends-"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
